{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "65a47340-96f7-4dd5-883b-ff240a426d98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65a47340-96f7-4dd5-883b-ff240a426d98",
        "outputId": "6429ccbe-ea56-4c6d-a8d7-c398c7cf1e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- author: string (nullable = true)\n",
            "\n",
            "+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|id     |text                                                                                                                                                                                                                                                                                                                                                |author|\n",
            "+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|id27763|How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.                                                                                                                                      |MWS   |\n",
            "|id13515|The surcingle hung in ribands from my body.                                                                                                                                                                                                                                                                                                         |EAP   |\n",
            "|id16737|\"He shall find that I can feel my injuries; he shall learn to dread my revenge\"\" A few days after he arrived.\"                                                                                                                                                                                                                                      |MWS   |\n",
            "|id19764|Herbert West needed fresh bodies because his life work was the reanimation of the dead.                                                                                                                                                                                                                                                             |HPL   |\n",
            "|id08441|To these speeches they gave, of course, their own interpretation; fancying, no doubt, that at all events I should come into possession of vast quantities of ready money; and provided I paid them all I owed, and a trifle more, in consideration of their services, I dare say they cared very little what became of either my soul or my carcass.|EAP   |\n",
            "+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"SpookyAuthorIdentification\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"12g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "# Load the CSV data into a Spark DataFrame\n",
        "file_path = \"train.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "df = df.sample(fraction=0.5, seed=42)\n",
        "# Show the schema and the first few rows of the Spark DataFrame\n",
        "df.printSchema()\n",
        "df.show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eac0c8f2-14e5-499e-b9ff-0e9b76c06308",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eac0c8f2-14e5-499e-b9ff-0e9b76c06308",
        "outputId": "eda94c3d-6b0f-4982-fca5-368924c7ae62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|tokens                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[how, lovely, is, spring, as, we, looked, from, windsor, terrace, on, the, sixteen, fertile, counties, spread, beneath,, speckled, by, happy, cottages, and, wealthier, towns,, all, looked, as, in, former, years,, heart, cheering, and, fair.]                                                                                                                                                                 |\n",
            "|[the, surcingle, hung, in, ribands, from, my, body.]                                                                                                                                                                                                                                                                                                                                                              |\n",
            "|[\"he, shall, find, that, i, can, feel, my, injuries;, he, shall, learn, to, dread, my, revenge\"\", a, few, days, after, he, arrived.\"]                                                                                                                                                                                                                                                                             |\n",
            "|[herbert, west, needed, fresh, bodies, because, his, life, work, was, the, reanimation, of, the, dead.]                                                                                                                                                                                                                                                                                                           |\n",
            "|[to, these, speeches, they, gave,, of, course,, their, own, interpretation;, fancying,, no, doubt,, that, at, all, events, i, should, come, into, possession, of, vast, quantities, of, ready, money;, and, provided, i, paid, them, all, i, owed,, and, a, trifle, more,, in, consideration, of, their, services,, i, dare, say, they, cared, very, little, what, became, of, either, my, soul, or, my, carcass.]|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import Tokenizer\n",
        "\n",
        "# Tokenize the text column\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
        "df_tokens = tokenizer.transform(df)\n",
        "\n",
        "# Show the tokenized text\n",
        "df_tokens.select(\"tokens\").show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "01f246fc-a85f-43a8-a09d-816e70ddff72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01f246fc-a85f-43a8-a09d-816e70ddff72",
        "outputId": "515aad4f-0b47-4c09-c3f0-8bfd6e3f6711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|filtered_tokens                                                                                                                                                                                                                                    |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath,, speckled, happy, cottages, wealthier, towns,, looked, former, years,, heart, cheering, fair.]                                                             |\n",
            "|[surcingle, hung, ribands, body.]                                                                                                                                                                                                                  |\n",
            "|[\"he, shall, find, feel, injuries;, shall, learn, dread, revenge\"\", days, arrived.\"]                                                                                                                                                               |\n",
            "|[herbert, west, needed, fresh, bodies, life, work, reanimation, dead.]                                                                                                                                                                             |\n",
            "|[speeches, gave,, course,, interpretation;, fancying,, doubt,, events, come, possession, vast, quantities, ready, money;, provided, paid, owed,, trifle, more,, consideration, services,, dare, say, cared, little, became, either, soul, carcass.]|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n",
        "\n",
        "# Customize stopwords list to include pronouns\n",
        "stopwords = StopWordsRemover.loadDefaultStopWords(\"english\") + ['I', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her']\n",
        "\n",
        "# Remove stopwords from the tokenized text\n",
        "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\", stopWords=stopwords)\n",
        "df_cleaned = remover.transform(df_tokens)\n",
        "\n",
        "# Show the cleaned tokens\n",
        "df_cleaned.select(\"filtered_tokens\").show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8b176dde-dcbc-4edd-bd29-79d42e29ba4b",
      "metadata": {
        "id": "8b176dde-dcbc-4edd-bd29-79d42e29ba4b"
      },
      "outputs": [],
      "source": [
        "#Stage 2 Feature Extraction\n",
        "\n",
        "#import required functions\n",
        "from pyspark.ml.feature import StopWordsRemover, Tokenizer\n",
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "#TF-IDF calculation\n",
        "vectorizer = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"vectorized_tokens\")\n",
        "idf = IDF(inputCol=\"vectorized_tokens\", outputCol=\"tfidf\")\n",
        "normalizer = Normalizer(inputCol=\"tfidf\", outputCol=\"normalized_features\")\n",
        "indexer = StringIndexer(inputCol=\"author\", outputCol=\"label\")\n",
        "\n",
        "#The dataframe has already gone through the tokenizer and remover steps at this point, so they don't need to\n",
        "#be included in the pipeline\n",
        "pipeline = Pipeline(stages=[vectorizer, idf, normalizer, indexer])\n",
        "\n",
        "processed_data = pipeline.fit(df_cleaned).transform(df_cleaned)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage 3 Machine Learning\n",
        "\n",
        "# Random Forest\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# Split the data\n",
        "train_data, test_data = processed_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"normalized_features\", numTrees=20)\n",
        "rf_model = rf.fit(train_data)\n",
        "\n",
        "predictions = rf_model.transform(test_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "5ikQUnA_7Ant"
      },
      "id": "5ikQUnA_7Ant",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with PCA\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "\n",
        "from pyspark.ml.feature import PCA\n",
        "\n",
        "#pca = PCA(k=100, inputCol=\"normalized_features\", outputCol=\"pca_features\")\n",
        "#processed_data = pca.fit(processed_data).transform(processed_data)\n",
        "\n",
        "logistic_regression = LogisticRegression(featuresCol=\"normalized_features\", labelCol=\"label\", maxIter=50)\n",
        "\n",
        "train_data, test_data = processed_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "\n",
        "lr_model = logistic_regression.fit(train_data)\n",
        "\n",
        "lr_predictions = lr_model.transform(test_data)"
      ],
      "metadata": {
        "id": "QSsNGz1AELpB"
      },
      "id": "QSsNGz1AELpB",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage 4 Evaluation\n",
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "# Random Forest Accuracy\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Random Forest Accuracy = {accuracy:.2f}\")\n",
        "\n",
        "# Logistic Regression AccuracyLogistic Regression Accuracy =  0.60\n",
        "\n",
        "\n",
        "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
        "print(f\"Logistic Regression Accuracy =  {lr_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "1mbqF-KJ9Dr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c47012-49cc-4f3b-81c2-74dc1e558824"
      },
      "id": "1mbqF-KJ9Dr1",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy = 0.37\n",
            "Logistic Regression Accuracy =  0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1L2FQkt8EGMr"
      },
      "id": "1L2FQkt8EGMr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}